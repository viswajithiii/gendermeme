---
title: "Error Analysis: GenderMeme May 19 2017"
author: "Poorna Kumar"
date: 5-19-2017
output: 
  html_document:
    toc: true
    toc_depth: 6
---

```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(stringr)
library(knitr)

return_outlet <- function(url) {
  if (str_detect(url, "techcrunch\\.c")) {
    return("TechCrunch")
  }
  if (str_detect(url, "washingtonpost\\.c")) {
    return("Washington Post")
  }
  if (str_detect(url, "nytimes\\.com")) {
    return("NYT")
  } 
  if (str_detect(url, "latimes\\.c")) {
    return("LA Times")
  }
  if (str_detect(url, "bloomberg\\.c")) {
    return("Bloomberg")
  }
}

error_data <- 
  read_tsv('/Users/Poorna/Desktop/Box Sync/Gendermeme/gendermeme/annotated/manual/ann_dump_Fri_May_19_00_59_45_2017.tsv')

error_data <-
  error_data %>% 
  filter(!(a_gender == "non-living" & where == "auto_only")) %>%
  filter(!(a_gender == "non-living" & str_detect(m_gender, "company"))) %>% 
  filter(!(where == "manual_only" & str_detect(m_gender, "company"))) %>% 
  filter(!(str_detect(name, "(anonymous)|(unnamed)|(unknown)"))) %>% 
  mutate(outlet = map_chr(url, return_outlet))
```

The error rates for people-detection are below:

```{r}
error_data %>% 
  group_by(outlet) %>% 
  mutate(n_articles = n_distinct(art_id)) %>% 
  count(n_articles, where) %>% 
  spread(key = where, value = n) %>% 
  ungroup() %>% 
  mutate(precision = both / (auto_only + both), recall = both / (both + manual_only)) %>% 
  arrange(desc(n_articles)) %>% 
  kable()
```

We now examine the error rates for gender detection.

First, let us look at those cases where a person was identified by automatically
as well as manually. We restrict our attention to people who were identified as
either `male` or `female`.

```{r}
error_data %>% 
  filter(where == "both", m_gender %in% c("male", "female")) %>% 
  count(m_gender, a_gender) %>% 
  group_by(m_gender) %>% 
  summarize(
    total = sum(n), 
    a_correct = sum(n[a_gender == m_gender]), 
    a_incorrect_none = sum(n[a_gender == "None"]),
    a_incorrect_opp_gender = sum(n[m_gender != a_gender & a_gender %in% c("male", "female")]),
    a_incorrect_non_living = sum(n[m_gender != a_gender & a_gender == "non-living"])
  ) %>% 
  mutate(
    perc_a_correct = a_correct * 100 / total,
    perc_a_incorrect_none = a_incorrect_none * 100 / total,
    perc_a_incorrect_opp_gender = a_incorrect_opp_gender * 100 / total,
    perc_a_incorrect_non_living = a_incorrect_non_living * 100 / total
  ) %>% 
  kable()
```


We find that a lot of men are being mis-tagged as women. Why is this?

Let's have a look at men who are tagged as women.

```{r}
error_data %>% 
  filter(where == "both", m_gender == "male", a_gender == "female") %>% 
  select(art_id, outlet, everything(), -url) %>% 
  kable()
```

Let's also look at men who are tagged as "None":

```{r}
error_data %>% 
  filter(where == "both", m_gender == "male", a_gender == "None") %>% 
  select(art_id, outlet, everything(), -url) %>% 
  kable()

```


We find that, quite frequently, "Trump" is being tagged as male by us and as "None"
by the computer. We suspect that this is because "Trump" appears in contexts like
"Trump administration", only once in the article, etc. A rule might be able to 
fix this issue.

Let us look at the gender-related accuracy once again:

```{r}
error_data %>% 
  filter(outlet %in% c("NYT", "Washington Post", "TechCrunch")) %>% 
  filter(where == "both", m_gender %in% c("male", "female")) %>% 
  group_by(outlet) %>% 
  count(m_gender, a_gender) %>% 
  group_by(outlet, m_gender) %>% 
  summarize(
    total = sum(n), 
    a_correct = sum(n[a_gender == m_gender]), 
    a_incorrect_none = sum(n[a_gender == "None"]),
    a_incorrect_opp_gender = sum(n[m_gender != a_gender & a_gender %in% c("male", "female")]),
    a_incorrect_non_living = sum(n[m_gender != a_gender & a_gender == "non-living"])
  ) %>% 
  mutate(
    perc_a_correct = a_correct * 100 / total,
    perc_a_incorrect_none = a_incorrect_none * 100 / total,
    perc_a_incorrect_opp_gender = a_incorrect_opp_gender * 100 / total,
    perc_a_incorrect_non_living = a_incorrect_non_living * 100 / total
  ) %>% 
  ungroup() %>% 
  kable()
```

Note that this is a slightly strange, and over-optimistic, metric. We are isolating 
only those people that WERE identified as people, and among those, finding the recall
for gender. However, some male and female people fall out of the pipeline at the person-detection
stage, so the above recall numbers are slightly inflated. Let's correct for this.


